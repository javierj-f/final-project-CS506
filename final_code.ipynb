{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f09c043",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mephem\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ephem\n",
    "from meteostat import Point, Daily\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import chi2_contingency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cdfb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Here we have our cities. \n",
    "\n",
    "    Our two cities on the east will be Boston, MA and Virginia Key, FL\n",
    "    Miami did not have a designated NOAA station, so the station in Virginia Key, Florida was the closest one. \n",
    "\n",
    "    Our two cities on the west coast will be Seattle, WA and Los Angeles, CA.\n",
    "    To have recent but consistent data, we have taken the data from the years 2019-2023'''\n",
    "\n",
    "cities = {\n",
    "    \"Seattle\": {\"lat\": 47.6062, \"lon\": -122.3321, \"threshold\": 13.45},\n",
    "    \"Florida\": {\"lat\": 25.7617, \"lon\": -80.1918, \"threshold\": 3.53},\n",
    "    \"Boston\": {\"lat\": 42.3601, \"lon\": -71.0589, \"threshold\": 12.5},\n",
    "    \"LA\": {\"lat\": 34.0522, \"lon\": -118.2437, \"threshold\": 6.99}\n",
    "}\n",
    "\n",
    "years = range(2019, 2024)\n",
    "data_folder = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670c0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will iterate through our data folder and pick out the csv files for each, loading it for use.\n",
    "\n",
    "def load_city_data(city_name):\n",
    "    dfs = []\n",
    "    for year in years:\n",
    "        file_path = f\"{data_folder}/tide_height_{city_name.lower()}_{year}.csv\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        df[\"Datetime\"] = pd.to_datetime(df[\"Date\"] + \" \" + df[\"Time (GMT)\"])\n",
    "        df = df.set_index(\"Datetime\").drop(columns=[\"Date\", \"Time (GMT)\", \"Preliminary (ft)\"])\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "# Since our csv files come with hourly data, we will reformat them to showcase daily mean tides, while also adding a flood-watch 0.5ft buffer.\n",
    "# We do NOT merge all 4 datasets into one big one because the minor flooding thresholds are different per city based on historic data.\n",
    "# Doing so can affect how we categorize what a flood instance is, because a flood in Seattle could be nowhere near a flood in Boston.\n",
    "\n",
    "def process_daily_tides(df, threshold):\n",
    "    daily_df = df.resample(\"D\").agg({\n",
    "        \"Predicted (ft)\": \"mean\",\n",
    "        \"Verified (ft)\": [\"mean\", \"max\", \"min\"]\n",
    "    })\n",
    "    daily_df.columns = [\"Predicted_mean\",\"Verified_mean\",\"Verified_max\",\"Verified_min\"]\n",
    "    \n",
    "    # Label minor floods and near-floods\n",
    "    daily_df[\"Minor_Flood\"] = daily_df[\"Verified_max\"] > threshold\n",
    "    buffer = 0.5\n",
    "    daily_df[\"Close_to_Flood\"] = (\n",
    "        (daily_df[\"Verified_max\"] > (threshold - buffer)) &\n",
    "        (daily_df[\"Verified_max\"] <= threshold)\n",
    "    )\n",
    "    return daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f126ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' These functions are key. \n",
    "\n",
    "    get_moon_phase uses pyephem to get the daily moon phases, which is easier than scrubbing through weather data.\n",
    "     \n",
    "    categorize_phase will be used for modeling. A moon that is less than 10% visible or more than 90% visible is a new or full moon.\n",
    "    We combine these because they are our parallel allignment phases, or phases that we predict will be more likely to cause flooding.\n",
    "    Less than 40 or greater than 60 is a quarter moon, and everything in-betweeen is intermediate. These are less likely to cause floodings\n",
    "    because they are phases where the allingment does not pull on the earth's tides.\n",
    "\n",
    "    Finally, add_moon_phase adds this to our datasets. \n",
    "\n",
    "'''\n",
    "\n",
    "def get_moon_phase(date):\n",
    "    if isinstance(date, pd.Timestamp):\n",
    "        date = date.date()\n",
    "    return ephem.Moon(date).phase\n",
    "\n",
    "def categorize_phase(phase):\n",
    "    if phase < 10 or phase > 90:\n",
    "        return \"New/Full Moon\"\n",
    "    elif 40 < phase < 60:\n",
    "        return \"Quarter Moon\"\n",
    "    else:\n",
    "        return \"Intermediate\"\n",
    "\n",
    "def add_moon_phase(df):\n",
    "    df[\"Moon_Phase\"] = [get_moon_phase(d) for d in df.index]\n",
    "    df[\"Phase_Category\"] = df[\"Moon_Phase\"].apply(categorize_phase)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666589a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' While we are not hyperfocusing on exploring the effects of earthly weather on tides, it is true that its effect is non-negligible.\n",
    "\n",
    "    We will use meteostat to get the weather data, and we will use some of its features.\n",
    "\n",
    "'''\n",
    "\n",
    "def add_weather_data(df, lat, lon):\n",
    "    point = Point(lat, lon)\n",
    "    weather_dfs = []\n",
    "    for year in years:\n",
    "        start = datetime(year, 1, 1)\n",
    "        end = datetime(year, 12, 31)\n",
    "        weather = Daily(point, start, end).fetch()\n",
    "        weather.index = pd.to_datetime(weather.index)\n",
    "        weather_dfs.append(weather)\n",
    "    weather_df = pd.concat(weather_dfs)\n",
    "    return df.merge(weather_df, left_index=True, right_index=True, how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50650e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will be our final datasets for each city.\n",
    "\n",
    "city_dfs = {}\n",
    "\n",
    "for city, info in cities.items():\n",
    "    raw_df = load_city_data(city)\n",
    "    daily_df = process_daily_tides(raw_df, info[\"threshold\"])\n",
    "    daily_df = add_moon_phase(daily_df)\n",
    "    final_df = add_weather_data(daily_df, info[\"lat\"], info[\"lon\"])\n",
    "    city_dfs[city] = final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808cb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of our cities, we will plot each day's instance, color-coded with that day's moon phase. \n",
    "# Instances above the threshold will be considered floods.\n",
    "\n",
    "colors = {\"New/Full Moon\":\"orange\", \"Quarter Moon\":\"green\", \"Intermediate\":\"purple\"}\n",
    "\n",
    "for city, df in city_dfs.items():\n",
    "    plt.figure(figsize=(12,6))\n",
    "    for phase in df[\"Phase_Category\"].unique():\n",
    "        subset = df[df[\"Phase_Category\"] == phase]\n",
    "        plt.scatter(subset.index, subset[\"Verified_max\"], color=colors[phase], alpha=0.5, label=phase)\n",
    "    plt.scatter(df[df[\"Minor_Flood\"]].index, df[df[\"Minor_Flood\"]][\"Verified_max\"], \n",
    "                facecolors='none', edgecolors='black', s=80, linewidths=1.5, label=\"Minor Flood\")\n",
    "    plt.axhline(y=cities[city][\"threshold\"], color='red', linestyle='--', label='Minor Flood Threshold')\n",
    "    plt.title(f\"{city} 2019-2023: Minor Floods by Moon Phase\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Max Verified Tide (ft)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51376428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will calculate the Moon Influence Score, which is a function\n",
    "# that will calculate the actual impact of the moon phase on the instances\n",
    "\n",
    "def compute_moon_influence(df):\n",
    "    floods = df[df[\"Minor_Flood\"]]\n",
    "    if len(floods) == 0:\n",
    "        return None\n",
    "    phase_counts = floods[\"Phase_Category\"].value_counts(normalize=True)\n",
    "    newfull = phase_counts.get(\"New/Full Moon\", 0)\n",
    "    quarter = phase_counts.get(\"Quarter Moon\", 0)\n",
    "    return newfull - quarter\n",
    "\n",
    "# Compute for each city\n",
    "moon_scores = []\n",
    "chi_results = []\n",
    "\n",
    "for city, df in city_dfs.items():\n",
    "    # Moon Influence Score\n",
    "    score = compute_moon_influence(df)\n",
    "    moon_scores.append({\"City\": city, \"Moon_Influence_Score\": score})\n",
    "    \n",
    "    # Chi-square test\n",
    "    contingency = pd.crosstab(df[\"Phase_Category\"], df[\"Minor_Flood\"])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "    chi_results.append({\"City\": city, \"Chi2\": chi2, \"p_value\": p, \"Degrees_of_Freedom\": dof})\n",
    "\n",
    "moon_scores_df = pd.DataFrame(moon_scores)\n",
    "chi_results_df = pd.DataFrame(chi_results)\n",
    "\n",
    "display(moon_scores_df)\n",
    "display(chi_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e13323",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_model_results = []\n",
    "\n",
    "for city, df in city_dfs.items():\n",
    "    \n",
    "    # drop rows with missing weather data\n",
    "    model_df = df.dropna(subset=[\"tavg\", \"wspd\", \"prcp\"])\n",
    "    \n",
    "    # encode moon phase as a categorical dummy variable\n",
    "    dummies = pd.get_dummies(model_df[\"Phase_Category\"], drop_first=True)\n",
    "\n",
    "    # select features\n",
    "    X = pd.concat([\n",
    "        model_df[[\"tavg\", \"wspd\", \"prcp\"]],  \n",
    "        dummies                              \n",
    "    ], axis=1)\n",
    "\n",
    "    y = model_df[\"Minor_Flood\"].astype(int)\n",
    "\n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # logistic regression model\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # evaluation\n",
    "    print(f\"\\n--- {city} ---\")\n",
    "    print(classification_report(y_test, model.predict(X_test)))\n",
    "\n",
    "    # save summary\n",
    "    coef_df = pd.DataFrame({\n",
    "        \"Feature\": X.columns,\n",
    "        \"Coefficient\": model.coef_[0]\n",
    "    })\n",
    "    \n",
    "    weather_model_results.append((city, coef_df))\n",
    "\n",
    "# display coefficients neatly\n",
    "for city, coef_df in weather_model_results:\n",
    "    print(f\"\\n=== {city}: Feature Importance (Logistic Regression Coefficients) ===\")\n",
    "    display(coef_df.sort_values(\"Coefficient\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca74c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_names, heatmap_matrix = [], []\n",
    "\n",
    "for city, df in city_dfs.items():\n",
    "    _df = df.copy()\n",
    "    _df[\"month\"] = _df.index.month\n",
    "    monthly = _df.groupby(\"month\")[\"Minor_Flood\"].mean().reindex(range(1,13), fill_value=0)\n",
    "    city_names.append(city)\n",
    "    heatmap_matrix.append(monthly.values)\n",
    "\n",
    "heatmap_matrix = np.array(heatmap_matrix)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.imshow(heatmap_matrix, cmap=\"coolwarm\", aspect=\"auto\")\n",
    "plt.colorbar(label=\"Flood Probability\")\n",
    "plt.yticks(range(len(city_names)), city_names)\n",
    "plt.xticks(range(12), range(1,13))\n",
    "plt.title(\"Seasonality of Floods (Probability of Minor Flood)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
